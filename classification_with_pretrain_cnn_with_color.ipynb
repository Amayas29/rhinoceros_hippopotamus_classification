{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_dataset\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "TRAIN_RATIO = 0.8\n",
    "N_CLASSES = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, train_labels = load_dataset(test=False, color=True)\n",
    "test_images, test_labels = load_dataset(test=True, color=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 3, 224, 224)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B, W, H = train_images.shape\n",
    "train_images = train_images.reshape((B, 1, W, H))\n",
    "train_images = np.repeat(train_images, 3, axis=1)\n",
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 3, 224, 224)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B, W, H = test_images.shape\n",
    "test_images = test_images.reshape((B, 1, W, H))\n",
    "test_images = np.repeat(test_images, 3, axis=1)\n",
    "\n",
    "test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gouhe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\gouhe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Charger un modèle pré-entraîné (ResNet18 dans cet exemple)\n",
    "model = models.resnet18(pretrained=True)\n",
    "\n",
    "# Geler les paramètres (poids) de toutes les couches du modèle\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Remplacer la dernière couche de classification\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 2) \n",
    "\n",
    "# Afficher le résumé du modèle (nécessite torchsummary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fc.out_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Époque 1, Perte d'entraînement: 0.5653, Perte de validation: 0.3633\n",
      "Époque 11, Perte d'entraînement: 0.0818, Perte de validation: 0.1085\n",
      "Époque 21, Perte d'entraînement: 0.0595, Perte de validation: 0.0778\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Charger un modèle pré-entraîné (ResNet18)\n",
    "model = models.resnet18(pretrained=True)\n",
    "\n",
    "# Geler les paramètres (poids) de toutes les couches du modèle\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Remplacer la dernière couche de classification\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 2)  # 2 classes pour la sortie\n",
    "\n",
    "# Supposons que train_images et train_labels soient vos données et étiquettes\n",
    "# train_images = ...\n",
    "# train_labels = ...\n",
    "\n",
    "# Diviser les données en ensembles d'entraînement et de validation\n",
    "train_images, val_images, train_labels, val_labels = train_test_split(\n",
    "    train_images, train_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Transformations\n",
    "\n",
    "train_images = torch.tensor(train_images, dtype=torch.float32)\n",
    "train_labels = torch.tensor(train_labels, dtype=torch.long)\n",
    "\n",
    "val_images = torch.tensor(val_images, dtype=torch.float32)\n",
    "val_labels = torch.tensor(val_labels, dtype=torch.long)\n",
    "\n",
    "# Appliquer les transformations et créer des DataLoader\n",
    "train_data = TensorDataset(train_images, train_labels)\n",
    "val_data = TensorDataset(val_images, val_labels)\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=32, shuffle=False)\n",
    "\n",
    "# Critère de perte et optimiseur\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=0.001)\n",
    "\n",
    "# Nombre d'époques pour l'entraînement\n",
    "num_epochs = 10\n",
    "liste_epoch  =[]\n",
    "liste_train_loss = []\n",
    "liste_val_loss = []\n",
    "# Boucle d'entraînement\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Mode d'entraînement\n",
    "    train_loss = 0.0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        optimizer.zero_grad()  # Réinitialiser les gradients\n",
    "        outputs = model(images)  # Passer les images dans le modèle\n",
    "        loss = criterion(outputs, labels)  # Calculer la perte\n",
    "        loss.backward()  # Rétropropagation\n",
    "        optimizer.step()  # Mise à jour des poids\n",
    "        train_loss += loss.item() * images.size(0)\n",
    "\n",
    "    # Évaluation\n",
    "    model.eval()  # Mode d'évaluation\n",
    "    val_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item() * images.size(0)\n",
    "\n",
    "    # Calculer la perte moyenne par époque\n",
    "    train_loss = train_loss / len(train_loader.dataset)\n",
    "    val_loss = val_loss / len(val_loader.dataset)\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Époque {epoch+1}, Perte d\\'entraînement: {train_loss:.4f}, Perte de validation: {val_loss:.4f}')\n",
    "    liste_epoch.append(liste_epoch)\n",
    "    liste_train_loss.append(liste_train_loss)\n",
    "    liste_val_loss.append(liste_val_loss)\n",
    "# Le modèle est maintenant entraîné et peut être utilisé pour des prédictions ou sauvegardé\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = torch.tensor(test_images, dtype=torch.float32)\n",
    "test_labels = torch.tensor(test_labels, dtype=torch.long)\n",
    "\n",
    "test_dataset = TensorDataset(test_images, test_labels)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Précision sur les données de test: 97.50%\n"
     ]
    }
   ],
   "source": [
    "# Calculer la précision sur les données de test\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "model.eval()  # Mettre le modèle en mode d'évaluation\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f'Précision sur les données de test: {accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création du graphique\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(liste_epoch, liste_train_loss, label='Perte d\\'entraînement')\n",
    "plt.plot(liste_epoch, liste_val_loss, label='Perte de validation', linestyle='--')\n",
    "\n",
    "plt.xlabel('Époques')\n",
    "plt.ylabel('Perte')\n",
    "plt.title('Perte d\\'entraînement et de validation au fil des époques')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
